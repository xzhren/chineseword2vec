{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 对wiki中文词库数据的导出\n",
    "- 目标：防止内存过度使用\n",
    "- 导出数据包括：\n",
    "  - zh_wiki_id：id表示的中文单词wiki文章，一行\n",
    "  - word_to_id.pkl：中文单词到id的映射词典\n",
    "  - id_to_word.pkl：id到中文单词的映射词典\n",
    "  - word_count.pkl：中文单词的出现次数的词典"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import collections\n",
    "import math\n",
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "import random\n",
    "from tempfile import gettempdir\n",
    "import zipfile\n",
    "\n",
    "import numpy as np\n",
    "from six.moves import urllib\n",
    "from six.moves import xrange  # pylint: disable=redefined-builtin\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "\n",
    "from tensorflow.contrib.tensorboard.plugins import projector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_data(filename):\n",
    "    \"\"\"Extract the first file enclosed in a zip file as a list of words.\"\"\"\n",
    "    with open(filename) as f:\n",
    "        data = f.readlines()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4056734/4056734 [00:32<00:00, 126585.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size 222822535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data = read_data(\"./data/zh_wiki_word_w_d\")\n",
    "vocabulary = []\n",
    "for line in tqdm(data):\n",
    "    line = line.strip()\n",
    "    for item in line.split():\n",
    "#         print(item)\n",
    "        vocabulary.append(item)\n",
    "#     break\n",
    "# vocabulary = [v for v in vocabulary]\n",
    "print('Data size', len(vocabulary))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "zh_wiki_word: 222822535 / line num: 4056734\n",
    "zh_wiki_word_w_d: 183765886 / line num: 4056734"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "做 头发 是 中国 大陆 互联网 流行语 之一 ， 该 词汇 发源 于 D 年 D 月 D 日 中国 大陆 娱乐圈 一个 爆炸 新闻 — — 李小璐 出轨 事件 ， 当天 当 民众 都 在 关注 各大 卫视 跨年 晚会 时 ， 李小璐 在 W 家中 过夜 的 视频 火遍 中国 娱乐圈 ， 而 贾乃亮 当晚 直播 说 李小璐 去 做 头发 了 ， 所以 不 在家 。 “ 做 头发 ” 梗 就此 而 来 ， 成为 继 娱乐圈 明星 们 晚上 关门 聊 剧本 之后 的 又 一 出轨 隐喻 。\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'。'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(data[-1])\n",
    "del data\n",
    "vocabulary[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['数学', '是', '利用', '符号语言', '研究', '数量', '结构', '变化', '以及', '空间']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2041017"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(vocabulary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('雷瓦乡', 1),\n",
       " ('星棱大', 1),\n",
       " ('玩网', 1),\n",
       " ('💧', 1),\n",
       " ('充浩是', 1),\n",
       " ('我鸡哥', 1),\n",
       " ('人狠话', 1),\n",
       " ('纹缘', 1),\n",
       " ('猥琐男', 1),\n",
       " ('普泛', 1)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_cnt = collections.Counter(vocabulary).most_common(2041017)\n",
    "word_cnt[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "191551\n"
     ]
    }
   ],
   "source": [
    "for index, (k,v) in enumerate(word_cnt):\n",
    "    if v <= 25:\n",
    "        print(index)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"data/word_count_w_d.pkl\", \"wb\") as f:\n",
    "    pickle.dump(word_cnt, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('鲍洪升', 5), ('赫利纳', 5), ('但泽号', 5), ('革共', 5), ('柯尚', 4)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "look_num = -2740\n",
    "word_cnt[:look_num][-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocabulary_size = 504175\n",
    "vocabulary_size = 510000 - 2740\n",
    "\n",
    "def build_dataset(words, n_words):\n",
    "    \"\"\"Process raw inputs into a dataset.\"\"\"\n",
    "    count = [['UNK', -1]]\n",
    "    count.extend(collections.Counter(words).most_common(n_words - 1))\n",
    "    dictionary = dict()\n",
    "    for word, _ in count:\n",
    "        dictionary[word] = len(dictionary)\n",
    "    data = list()\n",
    "    unk_count = 0\n",
    "    for word in words:\n",
    "        index = dictionary.get(word, 0)\n",
    "        if index == 0:  # dictionary['UNK']\n",
    "            unk_count += 1\n",
    "        data.append(index)\n",
    "    count[0][1] = unk_count\n",
    "    reversed_dictionary = dict(zip(dictionary.values(), dictionary.keys()))\n",
    "    return data, count, dictionary, reversed_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most common words (+UNK) [['UNK', 2297816], ('，', 14808459), ('的', 9437707), ('。', 8706775), ('D', 8592359)]\n",
      "Sample data [1348, 9, 501, 237319, 141, 894, 5, 499, 5, 331] ['数学', '是', '利用', '符号语言', '研究', '数量', '、', '结构', '、', '变化']\n"
     ]
    }
   ],
   "source": [
    "# Filling 4 global variables:\n",
    "# data - list of codes (integers from 0 to vocabulary_size-1).\n",
    "#   This is the original text but words are replaced by their codes\n",
    "# count - map of words(strings) to count of occurrences\n",
    "# dictionary - map of words(strings) to their codes(integers)\n",
    "# reverse_dictionary - maps codes(integers) to words(strings)\n",
    "data, count, dictionary, reverse_dictionary = build_dataset(vocabulary, vocabulary_size)\n",
    "del vocabulary  # Hint to reduce memory.\n",
    "print('Most common words (+UNK)', count[:5])\n",
    "print('Sample data', data[:10], [reverse_dictionary[i] for i in data[:10]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Most common words (+UNK) [['UNK', 2291206], ('的', 9437707), ('年', 2807078), ('在', 2679806), ('是', 2112111)]\n",
    "Sample data [1296, 4, 462, 235572, 116, 850, 460, 301, 53, 611] ['数学', '是', '利用', '符号语言', '研究', '数量', '结构', '变化', '以及', '空间']\n",
    "\n",
    "Most common words (+UNK) [['UNK', 2297816], ('，', 14808459), ('的', 9437707), ('。', 8706775), ('D', 8592359)]\n",
    "Sample data [1348, 9, 501, 237319, 141, 894, 5, 499, 5, 331] ['数学', '是', '利用', '符号语言', '研究', '数量', '、', '结构', '、', '变化']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('郝琼', 5),\n",
       " ('线古坑', 5),\n",
       " ('尼乡', 5),\n",
       " ('泰什蒂乡', 5),\n",
       " ('梅斐', 5),\n",
       " ('卢德姆', 5),\n",
       " ('鲍洪升', 5),\n",
       " ('赫利纳', 5),\n",
       " ('但泽号', 5),\n",
       " ('革共', 5)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"data/zh_wiki_id_w_d\", \"w\") as f:\n",
    "    context = [str(i) for i in data]\n",
    "    f.write(\" \".join(context))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"data/word_to_id_w_d.pkl\", \"wb\") as f:\n",
    "    pickle.dump(dictionary, f)\n",
    "with open(\"data/id_to_word_w_d.pkl\", \"wb\") as f:\n",
    "    pickle.dump(reverse_dictionary, f)\n",
    "# with open(\"data/word_count_w_d.pkl\", \"wb\") as f:\n",
    "#     pickle.dump(count, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Load Data Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "zh_wiki_id = open(\"data/zh_wiki_id\").readline()\n",
    "word_to_id = pickle.load(open(\"data/word_to_id.pkl\", \"rb\"))\n",
    "id_to_word = pickle.load(open(\"data/id_to_word.pkl\", \"rb\"))\n",
    "word_count = pickle.load(open(\"data/count.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "zh_wiki_id = open(\"data/zh_wiki_id_w_d\").readline()\n",
    "word_to_id = pickle.load(open(\"data/word_to_id_w_d.pkl\", \"rb\"))\n",
    "id_to_word = pickle.load(open(\"data/id_to_word_w_d.pkl\", \"rb\"))\n",
    "# word_count = pickle.load(open(\"data/count.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "507260"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_to_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getWord(data, num, data_index):\n",
    "    sub_data_string = data[data_index:data_index+num*(6+1)]\n",
    "    print(sub_data_string)\n",
    "    result = []\n",
    "    for index, item in enumerate(sub_data_string.split()):\n",
    "        if index == num: break\n",
    "        data_index += len(item) + 1\n",
    "        result.append(int(item))\n",
    "    if len(result) < num:\n",
    "        return getWord(data, num, 0)\n",
    "    assert len(result) == num\n",
    "    return result, data_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "727934301"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(zh_wiki_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21556\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([21556], 727934302)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getWord(zh_wiki_id, 1, 727934301-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_batch(batch_size, skip_window, num_skips):\n",
    "    global data_index\n",
    "    assert batch_size % num_skips == 0\n",
    "    assert num_skips <= 2 * skip_window\n",
    "    batch = np.ndarray(shape=(batch_size, num_skips), dtype=np.int32)\n",
    "    labels = np.ndarray(shape=(batch_size, 1), dtype=np.int32)\n",
    "    span = 2 * skip_window + 1  # [ skip_window target skip_window ]\n",
    "    assert batch_size >= span\n",
    "    buffer = collections.deque(maxlen=span)  # pylint: disable=redefined-builtin\n",
    "#     if data_index + span*(6+1) > len(data):\n",
    "#         data_index = 0\n",
    "    result, data_index = getWord(zh_wiki_id, span, data_index)\n",
    "    buffer.extend(result)\n",
    "#     data_index += span\n",
    "    for i in range(batch_size):\n",
    "#         print(data_index, data_index + span, buffer)\n",
    "        context_words = [w for w in range(span) if w != skip_window]\n",
    "#         words_to_use = random.sample(context_words, num_skips)\n",
    "        # context tokens are just all the tokens in buffer except the target\n",
    "#         batch[i, :] = [token for idx, token in enumerate(buffer) if idx != context_window]\n",
    "#         batch[i, :] = [buffer[token] for idx, token in enumerate(words_to_use)]\n",
    "        batch[i, :] = [buffer[token] for idx, token in enumerate(context_words)]\n",
    "        labels[i, 0] = buffer[skip_window]\n",
    "        result, data_index = getWord(zh_wiki_id, 1, data_index)\n",
    "        buffer.append(result[0])\n",
    "        if data_index > len(zh_wiki_id):\n",
    "            result, data_index = getWord(zh_wiki_id, span-1, 0)\n",
    "            buffer.extend(result)\n",
    "        if i == batch_size - span:\n",
    "            last_index = data_index\n",
    "#         data_index = (data_index + 1) % len(data)\n",
    "        \n",
    "#         print(\"batch:\", [i for i in batch], \"\\nlabels:\", [ j for i in labels for j in i])\n",
    "#         print(\"batch:\", batch[i], \"\\nlabels:\", labels[i])\n",
    "    # Backtrack a little bit to avoid skipping words in the end of a batch\n",
    "#     data_index = (data_index + len(data) - span) % len(data)\n",
    "    data_index = last_index\n",
    "#     print(\"batch:\", batch, \"\\nlabels:\", labels)\n",
    "    return batch, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73 68 7400 2 8354 41 690 23 262 271 9578 10038 190 2 3132 3 607 1348 2 1908 1\n",
      "10038 1\n",
      "190 2 3\n",
      "2 3132 \n",
      "3132 3 \n",
      "3 607 1\n",
      "607 134\n",
      "1348 2 \n",
      "2 1908 \n",
      "1908 18\n",
      "18 1677\n",
      "1677 34\n",
      "3419 55\n",
      "550 18 \n",
      "18 680 \n",
      "680 253\n",
      "253 23 \n",
      "23 1718\n",
      "17185 2\n",
      "2 17826\n",
      "17826 3\n",
      "318\n",
      "batch： (20, 10)\n",
      "labels： (20, 1)\n",
      "73 以及 68 从 7400 选定 2 的 8354 公理 690 定义 23 中 262 建立 271 起 9578 严谨 -> 41 及\n",
      "68 从 7400 选定 2 的 8354 公理 41 及 23 中 262 建立 271 起 9578 严谨 10038 推导 -> 690 定义\n",
      "7400 选定 2 的 8354 公理 41 及 690 定义 262 建立 271 起 9578 严谨 10038 推导 190 出 -> 23 中\n",
      "2 的 8354 公理 41 及 690 定义 23 中 271 起 9578 严谨 10038 推导 190 出 2 的 -> 262 建立\n",
      "8354 公理 41 及 690 定义 23 中 262 建立 9578 严谨 10038 推导 190 出 2 的 3132 定理 -> 271 起\n",
      "41 及 690 定义 23 中 262 建立 271 起 10038 推导 190 出 2 的 3132 定理 3 。 -> 9578 严谨\n",
      "690 定义 23 中 262 建立 271 起 9578 严谨 190 出 2 的 3132 定理 3 。 607 基础 -> 10038 推导\n",
      "23 中 262 建立 271 起 9578 严谨 10038 推导 2 的 3132 定理 3 。 607 基础 1348 数学 -> 190 出\n",
      "262 建立 271 起 9578 严谨 10038 推导 190 出 3132 定理 3 。 607 基础 1348 数学 2 的 -> 2 的\n",
      "271 起 9578 严谨 10038 推导 190 出 2 的 3 。 607 基础 1348 数学 2 的 1908 知识 -> 3132 定理\n",
      "9578 严谨 10038 推导 190 出 2 的 3132 定理 607 基础 1348 数学 2 的 1908 知识 18 与 -> 3 。\n",
      "10038 推导 190 出 2 的 3132 定理 3 。 1348 数学 2 的 1908 知识 18 与 1677 运用 -> 607 基础\n",
      "190 出 2 的 3132 定理 3 。 607 基础 2 的 1908 知识 18 与 1677 运用 3419 总是 -> 1348 数学\n",
      "2 的 3132 定理 3 。 607 基础 1348 数学 1908 知识 18 与 1677 运用 3419 总是 550 个人 -> 2 的\n",
      "3132 定理 3 。 607 基础 1348 数学 2 的 18 与 1677 运用 3419 总是 550 个人 18 与 -> 1908 知识\n",
      "3 。 607 基础 1348 数学 2 的 1908 知识 1677 运用 3419 总是 550 个人 18 与 680 团体 -> 18 与\n",
      "607 基础 1348 数学 2 的 1908 知识 18 与 3419 总是 550 个人 18 与 680 团体 253 生活 -> 1677 运用\n",
      "1348 数学 2 的 1908 知识 18 与 1677 运用 550 个人 18 与 680 团体 253 生活 23 中 -> 3419 总是\n",
      "2 的 1908 知识 18 与 1677 运用 3419 总是 18 与 680 团体 253 生活 23 中 17185 不可或缺 -> 550 个人\n",
      "1908 知识 18 与 1677 运用 3419 总是 550 个人 680 团体 253 生活 23 中 17185 不可或缺 2 的 -> 18 与\n"
     ]
    }
   ],
   "source": [
    "# data_index = 0\n",
    "\n",
    "batch, labels = generate_batch(batch_size=20, skip_window=5, num_skips=2*5)\n",
    "print(data_index)\n",
    "print(\"batch：\", batch.shape)\n",
    "print(\"labels：\", labels.shape)\n",
    "for i in range(20):\n",
    "    print(batch[i, 0], id_to_word[batch[i, 0]],\n",
    "          batch[i, 1], id_to_word[batch[i, 1]],\n",
    "          batch[i, 2], id_to_word[batch[i, 2]],\n",
    "          batch[i, 3], id_to_word[batch[i, 3]],\n",
    "          batch[i, 4], id_to_word[batch[i, 4]],\n",
    "          batch[i, 5], id_to_word[batch[i, 5]],\n",
    "          batch[i, 6], id_to_word[batch[i, 6]],\n",
    "          batch[i, 7], id_to_word[batch[i, 7]],\n",
    "          batch[i, 8], id_to_word[batch[i, 8]],\n",
    "          batch[i, 9], id_to_word[batch[i, 9]],\n",
    "          '->', labels[i, 0], id_to_word[labels[i, 0]])\n",
    "# for i in range(8):\n",
    "#     print(batch[i], reverse_dictionary[batch[i]], '->', labels[i, 0],\n",
    "#         reverse_dictionary[labels[i, 0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21 273 4340 294 6398 119 858 197 49216 77 1 11664 53 48 7268 1 8205 26 649 12\n",
      "11664 5\n",
      "53 48 7\n",
      "48 7268\n",
      "7268 1 \n",
      "1 8205 \n",
      "8205 26\n",
      "26 649 \n",
      "649 12 \n",
      "12 235 \n",
      "235 244\n",
      "244 942\n",
      "9420 98\n",
      "9874 16\n",
      "163 1 3\n",
      "1 3057 \n",
      "3057 56\n",
      "567 129\n",
      "1296 1 \n",
      "1 1851 \n",
      "1851 9 \n",
      "249\n",
      "batch： (20, 10)\n",
      "labels： (20, 1)\n",
      "21 而 273 产生 273 数学家 273 们 273 拓展 273 概念 273 为了 273 公式化 273 新 273 的 -> 119 这些\n",
      "273 产生 4340 数学家 4340 们 4340 拓展 4340 这些 4340 为了 4340 公式化 4340 新 4340 的 4340 猜想 -> 858 概念\n",
      "4340 数学家 294 们 294 拓展 294 这些 294 概念 294 公式化 294 新 294 的 294 猜想 294 以及 -> 197 为了\n",
      "294 们 6398 拓展 6398 这些 6398 概念 6398 为了 6398 新 6398 的 6398 猜想 6398 以及 6398 从 -> 49216 公式化\n",
      "6398 拓展 119 这些 119 概念 119 为了 119 公式化 119 的 119 猜想 119 以及 119 从 119 选定 -> 77 新\n",
      "119 这些 858 概念 858 为了 858 公式化 858 新 858 猜想 858 以及 858 从 858 选定 858 的 -> 1 的\n",
      "858 概念 197 为了 197 公式化 197 新 197 的 197 以及 197 从 197 选定 197 的 197 公理 -> 11664 猜想\n",
      "197 为了 49216 公式化 49216 新 49216 的 49216 猜想 49216 从 49216 选定 49216 的 49216 公理 49216 及 -> 53 以及\n",
      "49216 公式化 77 新 77 的 77 猜想 77 以及 77 选定 77 的 77 公理 77 及 77 定义 -> 48 从\n",
      "77 新 1 的 1 猜想 1 以及 1 从 1 的 1 公理 1 及 1 定义 1 中 -> 7268 选定\n",
      "1 的 11664 猜想 11664 以及 11664 从 11664 选定 11664 公理 11664 及 11664 定义 11664 中 11664 建立 -> 1 的\n",
      "11664 猜想 53 以及 53 从 53 选定 53 的 53 及 53 定义 53 中 53 建立 53 起 -> 8205 公理\n",
      "53 以及 48 从 48 选定 48 的 48 公理 48 定义 48 中 48 建立 48 起 48 严谨 -> 26 及\n",
      "48 从 7268 选定 7268 的 7268 公理 7268 及 7268 中 7268 建立 7268 起 7268 严谨 7268 推导 -> 649 定义\n",
      "7268 选定 1 的 1 公理 1 及 1 定义 1 建立 1 起 1 严谨 1 推导 1 出 -> 12 中\n",
      "1 的 8205 公理 8205 及 8205 定义 8205 中 8205 起 8205 严谨 8205 推导 8205 出 8205 的 -> 235 建立\n",
      "8205 公理 26 及 26 定义 26 中 26 建立 26 严谨 26 推导 26 出 26 的 26 定理 -> 244 起\n",
      "26 及 649 定义 649 中 649 建立 649 起 649 推导 649 出 649 的 649 定理 649 基础 -> 9420 严谨\n",
      "649 定义 12 中 12 建立 12 起 12 严谨 12 出 12 的 12 定理 12 基础 12 数学 -> 9874 推导\n",
      "12 中 235 建立 235 起 235 严谨 235 推导 235 的 235 定理 235 基础 235 数学 235 的 -> 163 出\n"
     ]
    }
   ],
   "source": [
    "# data_index = 0\n",
    "\n",
    "batch, labels = generate_batch(batch_size=20, skip_window=5, num_skips=2*5)\n",
    "print(data_index)\n",
    "print(\"batch：\", batch.shape)\n",
    "print(\"labels：\", labels.shape)\n",
    "for i in range(20):\n",
    "    print(batch[i, 0], id_to_word[batch[i, 0]],\n",
    "          batch[i, 1], id_to_word[batch[i, 1]],\n",
    "          batch[i, 1], id_to_word[batch[i, 2]],\n",
    "          batch[i, 1], id_to_word[batch[i, 3]],\n",
    "          batch[i, 1], id_to_word[batch[i, 4]],\n",
    "          batch[i, 1], id_to_word[batch[i, 5]],\n",
    "          batch[i, 1], id_to_word[batch[i, 6]],\n",
    "          batch[i, 1], id_to_word[batch[i, 7]],\n",
    "          batch[i, 1], id_to_word[batch[i, 8]],\n",
    "          batch[i, 1], id_to_word[batch[i, 9]],\n",
    "          '->', labels[i, 0], id_to_word[labels[i, 0]])\n",
    "# for i in range(8):\n",
    "#     print(batch[i], reverse_dictionary[batch[i]], '->', labels[i, 0],\n",
    "#         reverse_dictionary[labels[i, 0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
