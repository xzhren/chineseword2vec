{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import collections\n",
    "import math\n",
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "import random\n",
    "from tempfile import gettempdir\n",
    "import zipfile\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from six.moves import urllib\n",
    "from six.moves import xrange  # pylint: disable=redefined-builtin\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pickle\n",
    "\n",
    "from tensorflow.contrib.tensorboard.plugins import projector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "zh_wiki_id = open(\"data/zh_wiki_id_w_d\").readline()\n",
    "word_to_id = pickle.load(open(\"data/word_to_id_w_d.pkl\", \"rb\"))\n",
    "id_to_word = pickle.load(open(\"data/id_to_word_w_d.pkl\", \"rb\"))\n",
    "word_count = pickle.load(open(\"data/word_count_w_d.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(507260, 507260, 862838467)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(id_to_word), len(word_to_id), len(zh_wiki_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getWord(data, num, data_index):\n",
    "    sub_data_string = data[data_index:data_index+num*(6+1)]\n",
    "    result = []\n",
    "    for index, item in enumerate(sub_data_string.split()):\n",
    "        if index == num: break\n",
    "        data_index += len(item) + 1\n",
    "        result.append(int(item))\n",
    "    if len(result) < num:\n",
    "        return getWord(data, num, 0)\n",
    "    assert len(result) == num\n",
    "    return result, data_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_batch(batch_size, skip_window, num_skips):\n",
    "    global data_index\n",
    "    assert batch_size % num_skips == 0\n",
    "    assert num_skips <= 2 * skip_window\n",
    "    batch = np.ndarray(shape=(batch_size, num_skips), dtype=np.int32)\n",
    "    labels = np.ndarray(shape=(batch_size, 1), dtype=np.int32)\n",
    "    span = 2 * skip_window + 1  # [ skip_window target skip_window ]\n",
    "    assert batch_size >= span\n",
    "    buffer = collections.deque(maxlen=span)  # pylint: disable=redefined-builti\n",
    "    \n",
    "    result, data_index = getWord(zh_wiki_id, span, data_index)\n",
    "    buffer.extend(result)\n",
    "    \n",
    "    for i in range(batch_size):\n",
    "        context_words = [w for w in range(span) if w != skip_window]\n",
    "        batch[i, :] = [buffer[token] for idx, token in enumerate(context_words)]\n",
    "        labels[i, 0] = buffer[skip_window]\n",
    "        result, data_index = getWord(zh_wiki_id, 1, data_index)\n",
    "        buffer.append(result[0])\n",
    "        if data_index > len(zh_wiki_id):\n",
    "            result, data_index = getWord(zh_wiki_id, span-1, 0)\n",
    "            buffer.extend(result)\n",
    "        if i == batch_size - span:\n",
    "            last_index = data_index\n",
    "            \n",
    "    # Backtrack a little bit to avoid skipping words in the end of a batch\n",
    "    data_index = last_index\n",
    "    return batch, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1348 数学 501 利用 -> 9 是\n",
      "9 是 237319 符号语言 -> 501 利用\n",
      "501 利用 141 研究 -> 237319 符号语言\n",
      "237319 符号语言 894 数量 -> 141 研究\n",
      "141 研究 5 、 -> 894 数量\n",
      "894 数量 499 结构 -> 5 、\n",
      "5 、 5 、 -> 499 结构\n",
      "499 结构 331 变化 -> 5 、\n"
     ]
    }
   ],
   "source": [
    "data_index = 0\n",
    "\n",
    "batch, labels = generate_batch(batch_size=8, skip_window=1, num_skips=2*1)\n",
    "for i in range(8):\n",
    "    print(batch[i, 0], id_to_word[batch[i, 0]],\n",
    "          batch[i, 1], id_to_word[batch[i, 1]],\n",
    "          '->', labels[i, 0], id_to_word[labels[i, 0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def positional_encoding(inputs,\n",
    "                        num_units,\n",
    "                        zero_pad=True,\n",
    "                        scale=True,\n",
    "                        scope=\"positional_encoding\",\n",
    "                        reuse=None):\n",
    "    '''Sinusoidal Positional_Encoding.\n",
    "    Args:\n",
    "      inputs: A 2d Tensor with shape of (N, T).\n",
    "      num_units: Output dimensionality\n",
    "      zero_pad: Boolean. If True, all the values of the first row (id = 0) should be constant zero\n",
    "      scale: Boolean. If True, the output will be multiplied by sqrt num_units(check details from paper)\n",
    "      scope: Optional scope for `variable_scope`.\n",
    "      reuse: Boolean, whether to reuse the weights of a previous layer\n",
    "        by the same name.\n",
    "    Returns:\n",
    "        A 'Tensor' with one more rank than inputs's, with the dimensionality should be 'num_units'\n",
    "    '''\n",
    "\n",
    "    B, T, N = inputs.get_shape().as_list()\n",
    "    with tf.variable_scope(scope, reuse=reuse):\n",
    "        position_ind = tf.tile(tf.expand_dims(tf.range(T), 0), [N, 1])\n",
    "\n",
    "        # First part of the PE function: sin and cos argument\n",
    "        position_enc = np.array([\n",
    "            [pos / np.power(10000, 2.*i/num_units) for i in range(num_units)]\n",
    "            for pos in range(T)])\n",
    "\n",
    "        # Second part, apply the cosine to even columns and sin to odds.\n",
    "        position_enc[:, 0::2] = np.sin(position_enc[:, 0::2])  # dim 2i\n",
    "        position_enc[:, 1::2] = np.cos(position_enc[:, 1::2])  # dim 2i+1\n",
    "\n",
    "        # Convert to a tensor\n",
    "        lookup_table = tf.convert_to_tensor(position_enc)\n",
    "\n",
    "        if zero_pad:\n",
    "            lookup_table = tf.concat((tf.zeros(shape=[1, num_units]),\n",
    "                                      lookup_table[1:, :]), 0)\n",
    "        outputs = tf.nn.embedding_lookup(lookup_table, position_ind)\n",
    "        print(\"lookup_table:\", lookup_table)\n",
    "        print(\"position_ind:\", position_ind)\n",
    "        print(\"outputs:\", outputs)\n",
    "\n",
    "        if scale:\n",
    "            outputs = outputs * num_units**0.5\n",
    "\n",
    "#         return outputs\n",
    "        return tf.cast(outputs, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embeddings: <tf.Variable 'embeddings/Variable:0' shape=(507260, 100) dtype=float32_ref>\n",
      "embed: Tensor(\"embeddings/embedding_lookup:0\", shape=(100, 10, 100), dtype=float32)\n",
      "lookup_table: Tensor(\"position/positional_encoding/Const:0\", shape=(10, 100), dtype=float64)\n",
      "position_ind: Tensor(\"position/positional_encoding/Tile:0\", shape=(100, 10), dtype=int32)\n",
      "outputs: Tensor(\"position/positional_encoding/embedding_lookup:0\", shape=(100, 10, 100), dtype=float64)\n",
      "position embde: Tensor(\"position/add:0\", shape=(100, 10, 100), dtype=float32)\n",
      "attention_matmul: Tensor(\"self-attention/Tanh:0\", shape=(100, 10, 100), dtype=float32)\n",
      "attention: Tensor(\"self-attention/Softmax:0\", shape=(100, 10), dtype=float32)\n",
      "attention_context: Tensor(\"self-attention/Sum:0\", shape=(100, 100), dtype=float32)\n",
      "attention_mean: Tensor(\"self-attention/Mean:0\", shape=(), dtype=float32)\n",
      "attention_var: Tensor(\"self-attention/Mean_1:0\", shape=(), dtype=float32)\n",
      "valid_embeddings: Tensor(\"embedding_lookup:0\", shape=(22, 100), dtype=float32)\n",
      "normalized_embeddings: Tensor(\"truediv:0\", shape=(507260, 100), dtype=float32)\n",
      "similarity: Tensor(\"MatMul:0\", shape=(22, 507260), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 100\n",
    "# batch_size = 256\n",
    "embedding_size = 100    # Dimension of the embedding vector.\n",
    "skip_window = 5    # How many words to consider left and right.\n",
    "num_skips = 2*skip_window    # How many times to reuse an input to generate a label.\n",
    "num_sampled = 100    # Number of negative examples to sample.\n",
    "# num_sampled = 128    # Number of negative examples to sample.\n",
    "vocabulary_size = len(id_to_word)\n",
    "\n",
    "# We pick a random validation set to sample nearest neighbors. Here we limit the\n",
    "# validation samples to the words that have a low numeric ID, which by\n",
    "# construction are also the most frequent. These 3 variables are used only for\n",
    "# displaying model accuracy, they don't affect calculation.\n",
    "# valid_size = 16    # Random set of words to evaluate similarity on.\n",
    "# valid_window = 100    # Only pick dev samples in the head of the distribution.\n",
    "# valid_examples = np.random.choice(valid_window, valid_size, replace=False)\n",
    "valid_examples = list(range(1, 10))\n",
    "valid_examples = list(range(280, 291))\n",
    "valid_examples.extend(list(range(50000, 50011)))\n",
    "valid_size = len(valid_examples)\n",
    "\n",
    "graph = tf.Graph()\n",
    "\n",
    "with graph.as_default():\n",
    "\n",
    "    # Input data.\n",
    "    with tf.name_scope('inputs'):\n",
    "        train_inputs = tf.placeholder(tf.int32, shape=[batch_size, num_skips])\n",
    "        train_labels = tf.placeholder(tf.int32, shape=[batch_size, 1])\n",
    "        valid_dataset = tf.constant(valid_examples, dtype=tf.int32)\n",
    "\n",
    "    # Ops and variables pinned to the CPU because of missing GPU implementation\n",
    "#     with tf.device('/gpu:0'):\n",
    "    # Look up embeddings for inputs.\n",
    "    with tf.name_scope('embeddings'):\n",
    "        embeddings = tf.Variable(\n",
    "                tf.random_uniform([vocabulary_size, embedding_size], -1.0, 1.0))\n",
    "        print(\"embeddings:\", embeddings)\n",
    "        embed = tf.nn.embedding_lookup(embeddings, train_inputs)\n",
    "        print(\"embed:\", embed)\n",
    "        # take mean of embeddings of context words for context embedding\n",
    "#             embed_context = tf.reduce_mean(embed, 1)\n",
    "    with tf.name_scope(\"position\"):\n",
    "#         print(positional_encoding(embed, embedding_size, zero_pad=False))\n",
    "#         embed += positional_encoding(embed, embedding_size, zero_pad=False)\n",
    "#         print(\"position embde:\", embed)\n",
    "        embed_pos = embed + positional_encoding(embed, embedding_size, zero_pad=False)\n",
    "        print(\"position embde:\", embed_pos)\n",
    "\n",
    "    with tf.name_scope('self-attention'):\n",
    "        attention_size = embedding_size - 0\n",
    "#             attention_w = tf.Variable(tf.constant(1/num_skips, shape=[embedding_size, attention_size], dtype=tf.float32))\n",
    "        attention_w = tf.Variable(tf.ones(shape=[embedding_size, attention_size], dtype=tf.float32))\n",
    "        attention_b = tf.Variable(tf.zeros(shape=[attention_size], dtype=tf.float32))\n",
    "        attention_matmul = tf.tanh(tf.tensordot(embed_pos, attention_w, axes=[[2], [0]]) + attention_b)\n",
    "        print(\"attention_matmul:\", attention_matmul)\n",
    "\n",
    "#             attention_w_a = tf.Variable(tf.random_uniform([attention_size, 1], -1.0, 1.0))\n",
    "        attention_w_a = tf.Variable(tf.ones(shape=[attention_size], dtype=tf.float32))\n",
    "#             attention_matmul_reshape = tf.reshape(attention_matmul, [-1, attention_size])\n",
    "        attention = tf.nn.softmax(tf.tensordot(attention_matmul, attention_w_a, axes=[[2],[0]]))\n",
    "\n",
    "#             attention_matmul_a = tf.reshape(tf.matmul(attention_matmul, attention_w_a), [batch_size, num_skips, 1])\n",
    "#             print(\"attention_matmul_a:\", attention_matmul_a)\n",
    "# #             attention_matmul_a = tf.transpose(tf.matmul(attention_matmul, attention_w_a), perm=[0, 2, 1])\n",
    "#             attention = tf.transpose(tf.nn.softmax(attention_matmul_a, dim=1), perm=[0, 2, 1])\n",
    "        print(\"attention:\", attention)\n",
    "        attention_context = tf.reduce_sum(tf.multiply(embed, tf.expand_dims(attention, -1)), axis=1)\n",
    "#             attention_context = tf.squeeze(tf.matmul(attention, embed))\n",
    "#             attention_context = tf.reshape(attention_context, [batch_size, -1])\n",
    "        print(\"attention_context:\", attention_context)\n",
    "\n",
    "        # statistics attention info\n",
    "        attention_mean, attention_var = tf.nn.moments(attention, axes=[-1])\n",
    "        attention_mean = tf.reduce_mean(attention_mean)\n",
    "        attention_var = tf.reduce_mean(attention_var)\n",
    "        print(\"attention_mean:\", attention_mean)\n",
    "        print(\"attention_var:\", attention_var)\n",
    "\n",
    "    # Construct the variables for the NCE loss\n",
    "    with tf.name_scope('weights'):\n",
    "        nce_weights = tf.Variable(\n",
    "                tf.truncated_normal(\n",
    "                        [vocabulary_size, embedding_size],\n",
    "                        stddev=1.0 / math.sqrt(embedding_size)))\n",
    "    with tf.name_scope('biases'):\n",
    "        nce_biases = tf.Variable(tf.zeros([vocabulary_size]))\n",
    "\n",
    "    # Compute the average NCE loss for the batch.\n",
    "    # tf.nce_loss automatically draws a new sample of the negative labels each\n",
    "    # time we evaluate the loss.\n",
    "    # Explanation of the meaning of NCE loss:\n",
    "    #     http://mccormickml.com/2016/04/19/word2vec-tutorial-the-skip-gram-model/\n",
    "    with tf.name_scope('loss'):\n",
    "#         loss = tf.reduce_mean(\n",
    "#             tf.nn.nce_loss(nce_weights, nce_biases, embed_context, train_labels,\n",
    "#                            num_sampled, vocabulary_size))\n",
    "#         print(train_labels, embed_context)\n",
    "        loss = tf.reduce_mean(\n",
    "                tf.nn.nce_loss(\n",
    "                        weights=nce_weights,\n",
    "                        biases=nce_biases,\n",
    "                        labels=train_labels,\n",
    "#                         inputs=embed_context,\n",
    "                        inputs=attention_context,\n",
    "#                         labels=embed_context,\n",
    "#                         inputs=train_labels,\n",
    "                        num_sampled=num_sampled,\n",
    "                        num_classes=vocabulary_size))\n",
    "\n",
    "    # Add the loss value as a scalar to summary.\n",
    "    tf.summary.scalar('loss', loss)\n",
    "\n",
    "    # Construct the SGD optimizer using a learning rate of 1.0.\n",
    "    with tf.name_scope('optimizer'):\n",
    "        optimizer = tf.train.GradientDescentOptimizer(0.1).minimize(loss)\n",
    "#         optimizer = tf.train.AdamOptimizer(0.01).minimize(loss)\n",
    "\n",
    "    # Compute the cosine similarity between minibatch examples and all embeddings.\n",
    "    norm = tf.sqrt(tf.reduce_sum(tf.square(embeddings), 1, keep_dims=True))\n",
    "    normalized_embeddings = embeddings / norm\n",
    "    \n",
    "    valid_embeddings = tf.nn.embedding_lookup(normalized_embeddings, valid_dataset)\n",
    "    similarity = tf.matmul(valid_embeddings, normalized_embeddings, transpose_b=True)\n",
    "    print(\"valid_embeddings:\", valid_embeddings)\n",
    "    print(\"normalized_embeddings:\", normalized_embeddings)\n",
    "    print(\"similarity:\", similarity)\n",
    "\n",
    "    # Merge all summaries.\n",
    "    merged = tf.summary.merge_all()\n",
    "\n",
    "    # Add variable initializer.\n",
    "    init = tf.global_variables_initializer()\n",
    "\n",
    "    # Create a saver.\n",
    "    saver = tf.train.Saver()\n",
    "    saver_embed = tf.train.Saver([embeddings])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "751"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(word_count)['参展']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('骗人', '通讯设备', '李柱铭', '弹钢琴', '洁白', '塞纳省')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(id_to_word); start = 50000\n",
    "id_to_word[start], id_to_word[start+1], id_to_word[start+2], id_to_word[start+3], id_to_word[start+4], id_to_word[start+5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_index = 0\n",
    "num_steps = 20000001\n",
    "# num_steps = 1\n",
    "log_dir = \"./log_009_cbow_self-attention-position/\"\n",
    "log_embed_dir = \"./log_embeddings/\"\n",
    "\n",
    "base_dir = \"/home/renxinzhang/renxingzhang/chineseword2vec/logs/\"\n",
    "log_dir = base_dir+\"009_P_AWE_Slef_02/\"\n",
    "log_embed_dir = base_dir + \"word_embeddings_1.2kw/\"\n",
    "log_result_dir = \"/home/renxinzhang/renxingzhang/chineseword2vec/result/\"\n",
    "\n",
    "tfconfig = tf.ConfigProto()\n",
    "tfconfig.gpu_options.allow_growth = True\n",
    "\n",
    "with tf.Session(graph=graph, config=tfconfig) as session:\n",
    "    # Open a writer to write summaries.\n",
    "    writer = tf.summary.FileWriter(log_dir, session.graph)\n",
    "\n",
    "    # We must initialize all variables before we use them.\n",
    "    init.run()\n",
    "#     saver = tf.train.import_meta_graph('./checkpoint_dir/MyModel-1000.meta')\n",
    "#     saver.restore(session, tf.train.latest_checkpoint(log_dir))\n",
    "    saver_embed.restore(session, tf.train.latest_checkpoint(log_embed_dir))\n",
    "    print('Initialized')\n",
    "\n",
    "    average_loss = 0\n",
    "    avetage_attention = 0\n",
    "    std_attention = 0\n",
    "    start_index = 0 \n",
    "    for step in xrange(start_index, num_steps):\n",
    "        batch_inputs, batch_labels = generate_batch(batch_size, skip_window=skip_window, num_skips=num_skips)\n",
    "        feed_dict = {train_inputs: batch_inputs, train_labels: batch_labels}\n",
    "\n",
    "        # Define metadata variable.\n",
    "        run_metadata = tf.RunMetadata()\n",
    "\n",
    "        # We perform one update step by evaluating the optimizer op (including it\n",
    "        # in the list of returned values for session.run()\n",
    "        # Also, evaluate the merged op to get all summaries from the returned \"summary\" variable.\n",
    "        # Feed metadata variable to session for visualizing the graph in TensorBoard.\n",
    "        _, summary, loss_val, attention_val, std_val = session.run(\n",
    "                [optimizer, merged, loss, attention_mean, attention_var],\n",
    "                feed_dict=feed_dict,\n",
    "                run_metadata=run_metadata)\n",
    "        average_loss += loss_val\n",
    "        avetage_attention += attention_val\n",
    "        std_attention += std_val\n",
    "        \n",
    "#         print(\"embed:\", embed.eval(feed_dict=feed_dict))\n",
    "#         print(\"attention_w:\", attention_w.eval())\n",
    "#         print(\"attention_matmul:\", attention_matmul.eval(feed_dict=feed_dict))\n",
    "#         print(\"attention:\", attention.eval(feed_dict=feed_dict))\n",
    "#         print(\"attention_context:\", attention_context.eval(feed_dict=feed_dict))\n",
    "\n",
    "        # Add returned summaries to writer in each step.\n",
    "        writer.add_summary(summary, step)\n",
    "        # Add metadata to visualize the graph for the last run.\n",
    "        if step == (num_steps - 1):\n",
    "            writer.add_run_metadata(run_metadata, 'step%d' % step)\n",
    "\n",
    "        if step % 2000 == 0:\n",
    "            if step > 0 and step != start_index:\n",
    "                average_loss /= 2000\n",
    "                avetage_attention /= 2000\n",
    "                std_attention /= 2000\n",
    "            # The average loss is an estimate of the loss over the last 2000 batches.\n",
    "            print('Average loss at step ', step, ': ', average_loss, ': ', data_index)\n",
    "            average_loss = 0\n",
    "            print('Average attention at step ', step, ': ', avetage_attention)\n",
    "            print('Variance attention at step ', step, ': ', std_attention)\n",
    "            avetage_attention = 0\n",
    "            std_attention = 0\n",
    "#             print(\"attention:\", attention.eval(feed_dict=feed_dict)[:2])\n",
    "#             print(\"attention:\", attention.eval(feed_dict=feed_dict))\n",
    "\n",
    "        # Note that this is expensive (~20% slowdown if computed every 500 steps)\n",
    "        if step % 10000 == 0:\n",
    "            sim = similarity.eval()\n",
    "            for i in xrange(valid_size):\n",
    "                valid_word = id_to_word[valid_examples[i]]\n",
    "                top_k = 8    # number of nearest neighbors\n",
    "                nearest = (-sim[i, :]).argsort()[1:top_k + 1]\n",
    "                log_str = 'Nearest to %s:' % valid_word\n",
    "                for k in xrange(top_k):\n",
    "                    close_word = id_to_word[nearest[k]]\n",
    "                    log_str = '%s %s,' % (log_str, close_word)\n",
    "                print(log_str)\n",
    "                \n",
    "            # Save the model for checkpoints.\n",
    "            saver.save(session, os.path.join(log_dir, 'model.ckpt'), global_step=step)\n",
    "            \n",
    "        \n",
    "        if step % 1000000 == 0 and step != start_index:\n",
    "            word2vec = embeddings.eval()\n",
    "            print(word2vec.shape, type(word2vec))\n",
    "#             np.save(\"result/009#cbow_self-attention-position_0521_\"+str(step), word2vec)\n",
    "            np.save(log_result_dir+\"009_P_AWE_Slef_02_\"+str(step), word2vec)\n",
    "            \n",
    "    final_embeddings = normalized_embeddings.eval()\n",
    "\n",
    "    # Write corresponding labels for the embeddings.\n",
    "    with open(log_dir + '/metadata.tsv', 'w') as f:\n",
    "        for i in xrange(vocabulary_size):\n",
    "            f.write(id_to_word[i] + '\\n')\n",
    "\n",
    "    # Save the model for checkpoints.\n",
    "    saver.save(session, os.path.join(log_dir, 'model.ckpt'), global_step=step)\n",
    "\n",
    "    # Create a configuration for visualizing embeddings with the labels in TensorBoard.\n",
    "    config = projector.ProjectorConfig()\n",
    "    embedding_conf = config.embeddings.add()\n",
    "    embedding_conf.tensor_name = embeddings.name\n",
    "    projector.visualize_embeddings(writer, config)\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Average loss at step  0 :  535.846862793 :  385\n",
    "Average attention at step  0 :  0.10000000149\n",
    "Variance attention at step  0 :  0.0\n",
    "Nearest to 音乐: 流行音乐, 古典音乐, 电子音乐, 音乐创作, 乐曲, 爵士乐, 舞蹈, 唱片,\n",
    "Nearest to 地方: 区域, 地区, 偏远地区, 沿海地区, 内陆地区, 地点, 角落, 省厅,\n",
    "Nearest to 社会: 社会制度, 道德, 价值观, 人际关系, 贫富悬殊, 社会关系, 弱势群体, 现代性,\n",
    "Nearest to 服务: 运营, 营运, 咨询服务, 业务, 运作, 服务提供者, 业态, 服务项目,\n",
    "Nearest to 均: 皆, 都, 中均, 均会, 仍, 大都, 亦, 虽,\n",
    "Nearest to 型: W型, 式, 级, 形, 改型, 年型, 型号, -,\n",
    "Nearest to 学生: 同学, 师生, 教师, 考生, 学员, 女生, 大学生, 高中学生,\n",
    "Nearest to 今: 今属, 治今, 现属, 今为, 今新北市, 现, 今称, 今日,\n",
    "Nearest to 受到: 受, 深受, 遭到, 遭受, 倍受, 备受, 饱受, 未受,\n",
    "Nearest to 事件: 事故, 爆炸事件, 暴力事件, 惨案, 枪击案, 爆炸案, 血案, 惨剧,\n",
    "Nearest to 经济: 国民经济, 金融, 工商业, 经济繁荣, 经济社会, 农业, 金融业, 对外贸易,\n",
    "Nearest to 骗人: 查查, 同伙, 小妹, 方展, 凯子, 瑞斯, 调情, 前女友,\n",
    "Nearest to 通讯设备: 电子设备, 设备, 电子系统, 无线通讯, 装置, 电话机, 核生化, 全球定位系统,\n",
    "Nearest to 李柱铭: 刘慧卿, 何俊仁, 司徒华, 毛孟静, 社民连, 梁美芬, 郑经翰, 甘乃威,\n",
    "Nearest to 弹钢琴: 唱歌, 画画, 打网球, 跳舞, 钢琴, 弹奏, 写歌, 打篮球,\n",
    "Nearest to 洁白: 艳丽, 晶莹, 鲜美, 饱满, 清爽, 柔软, 鲜艳, 荷花,\n",
    "Nearest to 塞纳省: 阿尔卑斯省, 杉景胜, 加龙省, 利穆赞, 传统意义, 巴黎和会, 球会史, 电影史,\n",
    "Nearest to 国风: 花间, 楚文化, 文心雕龙, 李泰祥, 小雅, 元杂剧, 能岛, 卡芙特,\n",
    "Nearest to 灯具: 投影机, 灯光, 餐具, 闪光灯, 背光, 灯饰, 机械式, 密封式,\n",
    "Nearest to 应以: 只以, 需以, 系以, 以, 以非, 仅以, 能以, 不以,\n",
    "Nearest to 合二为一: 合而为一, 结合, 混为一谈, 分开, 连在一起, 连接起来, 紧密结合, 共用,\n",
    "Nearest to 瑛: 李英爱, 八神, 白眉, 翔, 木村拓哉, 赓, 初恋情人, 深田恭子,\n",
    "Average loss at step  2000 :  326.118571083 :  780407\n",
    "Average attention at step  2000 :  0.100000005182\n",
    "Variance attention at step  2000 :  0.0\n",
    "Average loss at step  4000 :  221.550058983 :  1562440\n",
    "Average attention at step  4000 :  0.100000005208\n",
    "Variance attention at step  4000 :  0.0\n",
    "Average loss at step  6000 :  180.629441563 :  2342496\n",
    "Average attention at step  6000 :  0.100000005335\n",
    "Variance attention at step  6000 :  0.0\n",
    "Average loss at step  8000 :  155.621790686 :  3145870\n",
    "Average attention at step  8000 :  0.10000000551\n",
    "Variance attention at step  8000 :  0.0\n",
    "Average loss at step  10000 :  135.889320656 :  3937978\n",
    "Average attention at step  10000 :  0.100000005253\n",
    "Variance attention at step  10000 :  0.0\n",
    "Nearest to 音乐: 流行音乐, 古典音乐, 电子音乐, 音乐创作, 乐曲, 爵士乐, 舞蹈, 乡村音乐,\n",
    "Nearest to 地方: 地区, 区域, 偏远地区, 人, 国家, UNK, 都, 机构,\n",
    "Nearest to 社会: 文化, 经济, 社会制度, W, 的, 社会学, 、, ，,\n",
    "Nearest to 服务: 运营, 营运, 咨询服务, 业务, 运作, 服务提供者, 工作, 业态,\n",
    "Nearest to 均: 皆, 都, 中均, 亦, 仍, 大都, 均会, 则,\n",
    "Nearest to 型: W型, 式, -, 级, 形, 改型, 型号, 年型,\n",
    "Nearest to 学生: 同学, 师生, 教师, 学员, 高中学生, 考生, 大学生, 中学生,\n",
    "Nearest to 今: 今属, 治今, 现属, 今为, 现, 今日, 今新北市, 今称,\n",
    "Nearest to 受到: 受, 深受, 遭到, 遭受, 倍受, 备受, 未受, 更受,\n",
    "Nearest to 事件: 事故, 暴力事件, 爆炸事件, 枪击案, 惨案, 爆炸案, 案件, 血案,\n",
    "Nearest to 经济: 金融, 国民经济, 社会, 农业, 工商业, 经济社会, 商业, 经济繁荣,\n",
    "Nearest to 骗人: 查查, 同伙, 小妹, 方展, 凯子, 瑞斯, 调情, 前女友,\n",
    "Nearest to 通讯设备: 电子设备, 设备, 电子系统, 无线通讯, 装置, 电话机, 核生化, 全球定位系统,\n",
    "Nearest to 李柱铭: 刘慧卿, 何俊仁, 司徒华, 毛孟静, 社民连, 梁美芬, 郑经翰, 甘乃威,\n",
    "Nearest to 弹钢琴: 唱歌, 画画, 打网球, 跳舞, 钢琴, 弹奏, 写歌, 打篮球,\n",
    "Nearest to 洁白: 艳丽, 晶莹, 鲜美, 饱满, 清爽, 柔软, 鲜艳, 荷花,\n",
    "Nearest to 塞纳省: 阿尔卑斯省, 杉景胜, 加龙省, 利穆赞, 传统意义, 巴黎和会, 球会史, 电影史,\n",
    "Nearest to 国风: 花间, 楚文化, 文心雕龙, 李泰祥, 小雅, 元杂剧, 能岛, 卡芙特,\n",
    "Nearest to 灯具: 投影机, 灯光, 餐具, 闪光灯, 背光, 灯饰, 机械式, 密封式,\n",
    "Nearest to 应以: 只以, 需以, 系以, 以非, 仅以, 能以, 不以, 即以,\n",
    "Nearest to 合二为一: 合而为一, 结合, 混为一谈, 分开, 连在一起, 连接起来, 紧密结合, 共用,\n",
    "Nearest to 瑛: 李英爱, 八神, 白眉, 翔, 木村拓哉, 赓, 初恋情人, 深田恭子,\n",
    "Average loss at step  12000 :  121.106598391 :  4719106\n",
    "Average attention at step  12000 :  0.10000000532\n",
    "Variance attention at step  12000 :  0.0\n",
    "Average loss at step  14000 :  110.842402222 :  5503359\n",
    "Average attention at step  14000 :  0.100000005331\n",
    "Variance attention at step  14000 :  0.0\n",
    "Average loss at step  16000 :  100.398558857 :  6292247\n",
    "Average attention at step  16000 :  0.100000005387\n",
    "Variance attention at step  16000 :  0.0\n",
    "Average loss at step  18000 :  90.7137951555 :  7071535\n",
    "Average attention at step  18000 :  0.100000005547\n",
    "Variance attention at step  18000 :  0.0\n",
    "Average loss at step  20000 :  84.1035817003 :  7850964\n",
    "Average attention at step  20000 :  0.100000005327\n",
    "Variance attention at step  20000 :  0.0\n",
    "Nearest to 音乐: 流行音乐, 古典音乐, 电子音乐, 音乐创作, 乐曲, 爵士乐, 艺术, 舞蹈,\n",
    "Nearest to 地方: 地区, 区域, 人, 国家, 都, UNK, 中, 或,\n",
    "Nearest to 社会: 文化, 经济, W, 、, UNK, 的, ，, 。,\n",
    "Nearest to 服务: 运营, 咨询服务, 营运, 业务, 运作, 工作, 服务提供者, 业态,\n",
    "Nearest to 均: 皆, 都, 亦, 中均, 仍, 则, 大都, 均会,\n",
    "Nearest to 型: W型, 式, -, 级, 形, 改型, 型号, 重型,\n",
    "Nearest to 学生: 师生, 同学, 教师, 高中学生, 学员, 大学生, 中学生, 考生,\n",
    "Nearest to 今: 今属, 治今, 现属, 今为, 现, 今日, 今新北市, 今称,\n",
    "Nearest to 受到: 受, 遭到, 深受, 遭受, 倍受, 备受, 更受, 未受,\n",
    "Nearest to 事件: 事故, 暴力事件, 爆炸事件, 枪击案, 惨案, 案件, 爆炸案, 惨剧,\n",
    "Nearest to 经济: 社会, 金融, 国民经济, 农业, 政府, 文化, 商业, 工商业,\n",
    "Nearest to 骗人: 查查, 同伙, 小妹, 方展, 凯子, 瑞斯, 调情, 前女友,\n",
    "Nearest to 通讯设备: 电子设备, 设备, 电子系统, 无线通讯, 装置, 电话机, 核生化, 全球定位系统,\n",
    "Nearest to 李柱铭: 刘慧卿, 何俊仁, 司徒华, 毛孟静, 社民连, 梁美芬, 郑经翰, 甘乃威,\n",
    "Nearest to 弹钢琴: 唱歌, 画画, 打网球, 跳舞, 钢琴, 弹奏, 写歌, 打篮球,\n",
    "Nearest to 洁白: 艳丽, 晶莹, 鲜美, 饱满, 清爽, 柔软, 鲜艳, 荷花,\n",
    "Nearest to 塞纳省: 阿尔卑斯省, 杉景胜, 加龙省, 利穆赞, 传统意义, 巴黎和会, 球会史, 电影史,\n",
    "Nearest to 国风: 花间, 楚文化, 文心雕龙, 李泰祥, 小雅, 元杂剧, 能岛, 卡芙特,\n",
    "Nearest to 灯具: 投影机, 灯光, 餐具, 闪光灯, 背光, 灯饰, 机械式, 密封式,\n",
    "Nearest to 应以: 只以, 需以, 系以, 以非, 仅以, 能以, 不以, 即以,\n",
    "Nearest to 合二为一: 合而为一, 结合, 混为一谈, 分开, 连在一起, 连接起来, 紧密结合, 共用,\n",
    "Nearest to 瑛: 李英爱, 八神, 白眉, 翔, 木村拓哉, 赓, 初恋情人, 深田恭子,\n",
    "Average loss at step  22000 :  78.6016870675 :  8647190\n",
    "Average attention at step  22000 :  0.100000005137\n",
    "Variance attention at step  22000 :  0.0\n",
    "Average loss at step  24000 :  72.7798590829 :  9434029\n",
    "Average attention at step  24000 :  0.100000005368\n",
    "Variance attention at step  24000 :  0.0\n",
    "Average loss at step  26000 :  68.5160555158 :  10208967\n",
    "Average attention at step  26000 :  0.100000005219\n",
    "Variance attention at step  26000 :  0.0\n",
    "Average loss at step  28000 :  63.4554456441 :  10994179\n",
    "Average attention at step  28000 :  0.100000005379\n",
    "Variance attention at step  28000 :  0.0\n",
    "Average loss at step  30000 :  59.4257241249 :  11780863\n",
    "Average attention at step  30000 :  0.100000005145\n",
    "Variance attention at step  30000 :  0.0\n",
    "Nearest to 音乐: 流行音乐, 古典音乐, 电子音乐, 音乐创作, 乐曲, 爵士乐, 艺术, 文化,\n",
    "Nearest to 地方: 地区, 区域, 人, 国家, 都, UNK, 或, 中,\n",
    "Nearest to 社会: 经济, 文化, UNK, W, 、, 之, 而, 的,\n",
    "Nearest to 服务: 运营, 咨询服务, 营运, 业务, 工作, 运作, 活动, 服务提供者,\n",
    "Nearest to 均: 皆, 都, 亦, 仍, 中均, 则, 大都, 仍然,\n",
    "Nearest to 型: W型, 式, -, 级, 形, 改型, 型号, 系,\n",
    "Nearest to 学生: 师生, 同学, 教师, 高中学生, 大学生, 学员, 中学生, 考生,\n",
    "Nearest to 今: 今属, 治今, 现属, 今为, 现, 今日, 今称, 今新北市,\n",
    "Nearest to 受到: 受, 遭到, 深受, 遭受, 倍受, 备受, 更受, 未受,\n",
    "Nearest to 事件: 事故, 暴力事件, 爆炸事件, 枪击案, 案件, 惨案, 爆炸案, 举动,\n",
    "Nearest to 经济: 社会, 金融, 政府, 农业, 文化, 国民经济, UNK, 工业,\n",
    "Nearest to 骗人: 查查, 同伙, 小妹, 方展, 凯子, 瑞斯, 调情, 前女友,\n",
    "Nearest to 通讯设备: 电子设备, 设备, 电子系统, 无线通讯, 装置, 电话机, 核生化, 全球定位系统,\n",
    "Nearest to 李柱铭: 刘慧卿, 何俊仁, 司徒华, 毛孟静, 社民连, 梁美芬, 郑经翰, 甘乃威,\n",
    "Nearest to 弹钢琴: 唱歌, 画画, 打网球, 跳舞, 钢琴, 弹奏, 写歌, 打篮球,\n",
    "Nearest to 洁白: 艳丽, 晶莹, 鲜美, 饱满, 清爽, 柔软, 鲜艳, 荷花,\n",
    "Nearest to 塞纳省: 阿尔卑斯省, 杉景胜, 加龙省, 利穆赞, 传统意义, 巴黎和会, 球会史, 电影史,\n",
    "Nearest to 国风: 花间, 楚文化, 文心雕龙, 李泰祥, 小雅, 元杂剧, 能岛, 卡芙特,\n",
    "Nearest to 灯具: 投影机, 灯光, 餐具, 闪光灯, 背光, 灯饰, 机械式, 密封式,\n",
    "Nearest to 应以: 只以, 需以, 系以, 以非, 仅以, 能以, 不以, 即以,\n",
    "Nearest to 合二为一: 合而为一, 结合, 混为一谈, 分开, 连在一起, 连接起来, 紧密结合, 共用,\n",
    "Nearest to 瑛: 李英爱, 八神, 白眉, 翔, 木村拓哉, 赓, 初恋情人, 深田恭子,\n",
    "Average loss at step  32000 :  54.8763011692 :  12567242\n",
    "Average attention at step  32000 :  0.100000005402\n",
    "Variance attention at step  32000 :  0.0\n",
    "Average loss at step  34000 :  53.4331241779 :  13351193\n",
    "Average attention at step  34000 :  0.100000005268\n",
    "Variance attention at step  34000 :  0.0\n",
    "Average loss at step  36000 :  49.0960876999 :  14141604\n",
    "Average attention at step  36000 :  0.100000005357\n",
    "Variance attention at step  36000 :  0.0\n",
    "Average loss at step  38000 :  45.9072646811 :  14931976\n",
    "Average attention at step  38000 :  0.10000000542\n",
    "Variance attention at step  38000 :  0.0\n",
    "Average loss at step  40000 :  43.1224056714 :  15722376\n",
    "Average attention at step  40000 :  0.100000005342\n",
    "Variance attention at step  40000 :  0.0\n",
    "Nearest to 音乐: 流行音乐, 古典音乐, 电子音乐, 音乐创作, 乐曲, 爵士乐, 艺术, 文化,\n",
    "Nearest to 地方: 地区, 区域, 人, 国家, 都, UNK, 或, 中,\n",
    "Nearest to 社会: 经济, 文化, UNK, 之, 、, W, 而, ；,\n",
    "Nearest to 服务: 运营, 咨询服务, 营运, 工作, 业务, 运作, 活动, 服务提供者,\n",
    "Nearest to 均: 皆, 都, 亦, 仍, 则, 中均, 便, 仍然,\n",
    "Nearest to 型: W型, 式, -, 级, 形, 改型, 系, 重型,\n",
    "Nearest to 学生: 师生, 同学, 教师, 高中学生, 大学生, 中学生, 学员, 考生,\n",
    "Nearest to 今: 今属, 治今, 今为, 现属, 今日, 现, 现今, 今称,\n",
    "Nearest to 受到: 受, 遭到, 深受, 遭受, 倍受, 备受, 更受, 未受,\n",
    "Nearest to 事件: 事故, 暴力事件, 爆炸事件, 案件, 枪击案, 惨案, 爆炸案, 举动,\n",
    "Nearest to 经济: 社会, 政府, 金融, 文化, UNK, 农业, ；, 工业,\n",
    "Nearest to 骗人: 查查, 同伙, 小妹, 方展, 凯子, 瑞斯, 调情, 前女友,\n",
    "Nearest to 通讯设备: 电子设备, 设备, 电子系统, 无线通讯, 装置, 电话机, 核生化, 全球定位系统,\n",
    "Nearest to 李柱铭: 刘慧卿, 何俊仁, 司徒华, 毛孟静, 社民连, 梁美芬, 郑经翰, 甘乃威,\n",
    "Nearest to 弹钢琴: 唱歌, 画画, 打网球, 跳舞, 钢琴, 弹奏, 写歌, 打篮球,\n",
    "Nearest to 洁白: 艳丽, 晶莹, 鲜美, 饱满, 清爽, 柔软, 鲜艳, 荷花,\n",
    "Nearest to 塞纳省: 阿尔卑斯省, 杉景胜, 加龙省, 利穆赞, 传统意义, 巴黎和会, 球会史, 电影史,\n",
    "Nearest to 国风: 花间, 楚文化, 文心雕龙, 李泰祥, 小雅, 元杂剧, 能岛, 卡芙特,\n",
    "Nearest to 灯具: 投影机, 灯光, 餐具, 闪光灯, 背光, 灯饰, 机械式, 密封式,\n",
    "Nearest to 应以: 只以, 需以, 系以, 以非, 仅以, 能以, 不以, 即以,\n",
    "Nearest to 合二为一: 合而为一, 结合, 混为一谈, 分开, 连在一起, 连接起来, 紧密结合, 共用,\n",
    "Nearest to 瑛: 李英爱, 八神, 白眉, 翔, 木村拓哉, 赓, 初恋情人, 深田恭子,\n",
    "Average loss at step  42000 :  41.2397918522 :  16505978\n",
    "Average attention at step  42000 :  0.100000005305\n",
    "Variance attention at step  42000 :  0.0\n",
    "Average loss at step  44000 :  39.8797826798 :  17296261\n",
    "Average attention at step  44000 :  0.100000005215\n",
    "Variance attention at step  44000 :  0.0\n",
    "Average loss at step  46000 :  37.0790673954 :  18081923\n",
    "Average attention at step  46000 :  0.100000005338\n",
    "Variance attention at step  46000 :  0.0\n",
    "Average loss at step  48000 :  35.6382392793 :  18875237\n",
    "Average attention at step  48000 :  0.100000005469\n",
    "Variance attention at step  48000 :  0.0\n",
    "Average loss at step  50000 :  33.2567264464 :  19653893\n",
    "Average attention at step  50000 :  0.100000005346\n",
    "Variance attention at step  50000 :  0.0\n",
    "Nearest to 音乐: 流行音乐, 古典音乐, 电子音乐, 音乐创作, 乐曲, 艺术, 文化, 爵士乐,\n",
    "Nearest to 地方: 地区, 区域, 人, 国家, 都, 或, UNK, 政府,\n",
    "Nearest to 社会: 经济, 文化, 之, UNK, 而, 、, 政府, ；,\n",
    "Nearest to 服务: 运营, 工作, 咨询服务, 营运, 业务, 活动, 运作, 服务提供者,\n",
    "Nearest to 均: 皆, 都, 亦, 仍, 则, 便, 仍然, 就,\n",
    "Nearest to 型: W型, 式, -, 级, 形, 系, 改型, 重型,\n",
    "Nearest to 学生: 师生, 同学, 教师, 高中学生, 大学生, 中学生, 学员, 考生,\n",
    "Nearest to 今: 治今, 今属, 今日, 现, 今为, 现属, 现今, 今称,\n",
    "Nearest to 受到: 受, 遭到, 深受, 遭受, 倍受, 备受, 更受, 未受,\n",
    "Nearest to 事件: 暴力事件, 事故, 案件, 爆炸事件, 现象, 枪击案, 行为, 惨案,\n",
    "Nearest to 经济: 社会, 政府, 文化, UNK, ；, 金融, 工业, ：,\n",
    "Nearest to 骗人: 查查, 同伙, 小妹, 方展, 凯子, 瑞斯, 调情, 前女友,\n",
    "Nearest to 通讯设备: 电子设备, 设备, 电子系统, 无线通讯, 装置, 电话机, 核生化, 全球定位系统,\n",
    "Nearest to 李柱铭: 刘慧卿, 何俊仁, 司徒华, 毛孟静, 社民连, 梁美芬, 郑经翰, 甘乃威,\n",
    "Nearest to 弹钢琴: 唱歌, 画画, 打网球, 跳舞, 钢琴, 弹奏, 写歌, 打篮球,\n",
    "Nearest to 洁白: 艳丽, 晶莹, 鲜美, 饱满, 清爽, 柔软, 鲜艳, 荷花,\n",
    "Nearest to 塞纳省: 阿尔卑斯省, 杉景胜, 加龙省, 利穆赞, 传统意义, 巴黎和会, 球会史, 电影史,\n",
    "Nearest to 国风: 花间, 楚文化, 文心雕龙, 李泰祥, 小雅, 元杂剧, 能岛, 卡芙特,\n",
    "Nearest to 灯具: 投影机, 灯光, 餐具, 闪光灯, 背光, 灯饰, 机械式, 密封式,\n",
    "Nearest to 应以: 只以, 需以, 系以, 以非, 仅以, 能以, 不以, 即以,\n",
    "Nearest to 合二为一: 合而为一, 结合, 混为一谈, 分开, 连在一起, 连接起来, 紧密结合, 共用,\n",
    "Nearest to 瑛: 李英爱, 八神, 白眉, 翔, 木村拓哉, 赓, 初恋情人, 深田恭子,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
